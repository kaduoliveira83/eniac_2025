# -*- coding: utf-8 -*-
"""lstm_artigo

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uuh6TbwKXR71yofceMBd0kXlzhLHjXvH
"""

# =====================
# 1. IMPORTAÇÃO DAS BIBLIOTECAS
# =====================
import optuna
import time
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from torch.utils.data import DataLoader, TensorDataset
import os

# =====================
# 2. CONFIGURAÇÕES INICIAIS
# =====================
optuna.logging.set_verbosity(optuna.logging.WARNING)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

save_path = "/media/work/carlosoliveira/resultados_modelos_lstm"
os.makedirs(save_path, exist_ok=True)

# =====================
# 3. LEITURA E CONVERSÃO TEMPORAL DOS DADOS
# =====================
dados = pd.read_csv('/media/work/carlosoliveira/id_21_completo.csv')
dados['ds'] = pd.to_datetime(dados['ds'], errors='coerce')

# =====================
# 4. SEPARAÇÃO TEMPORAL DOS DADOS
# =====================
valores = dados[['delay_60']].values.reshape(-1, 1)
split_1 = int(len(valores) * 0.7)
split_2 = int(len(valores) * 0.85)
valores_treino = valores[:split_1]
valores_validacao = valores[split_1:split_2]
valores_teste = valores[split_2:]

# =====================
# 5. NORMALIZAÇÃO DOS DADOS
# =====================
scaler = StandardScaler()
scaler.fit(valores_treino)
valores_treino = scaler.transform(valores_treino)
valores_validacao = scaler.transform(valores_validacao)
valores_teste = scaler.transform(valores_teste)

# =====================
# 6. GERAÇÃO DE JANELAS DESLIZANTES
# =====================
def gerar_janelas(data, tamanho_janela, horizonte_previsao):
    X, y = [], []
    for i in range(len(data) - tamanho_janela - horizonte_previsao + 1):
        X.append(data[i:i + tamanho_janela])
        y.append(data[i + tamanho_janela:i + tamanho_janela + horizonte_previsao])
    X = np.array(X).reshape(-1, tamanho_janela, 1)
    y = np.array(y).reshape(-1, horizonte_previsao)
    return X, y

# =====================
# 7. MODELO LSTM
# =====================
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, dropout, output_size):
        super().__init__()
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            dropout=dropout if num_layers>1 else 0.0,
            batch_first=True
        )
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.lstm(x)          # out: (batch, seq_len, hidden_size)
        out = out[:, -1, :]            # pega a última saída
        return self.fc(out)

# =====================
# 8. TREINAMENTO COM EARLY STOPPING
# =====================
def run_model(tamanho_janela, horizonte_previsao, X_train, y_train, X_val, y_val,
              hidden_size, num_layers, dropout, lr,
              epochs=100, patience=10):
    model = LSTMModel(1, hidden_size, num_layers, dropout, horizonte_previsao).to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    train_ds = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))
    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)

    best_loss = float('inf')
    wait = 0
    for epoch in range(epochs):
        model.train()
        for xb, yb in train_loader:
            xb, yb = xb.to(device), yb.to(device)
            optimizer.zero_grad()
            preds = model(xb)
            loss = criterion(preds, yb)
            loss.backward()
            optimizer.step()
        model.eval()
        with torch.no_grad():
            val_preds = model(torch.Tensor(X_val).to(device))
            val_loss = criterion(val_preds, torch.Tensor(y_val).to(device)).item()
        if val_loss < best_loss:
            best_loss = val_loss
            wait = 0
        else:
            wait += 1
            if wait >= patience:
                break
    return model

# =====================
# 9. OBJETIVO OPTUNA (JANELA & HORIZONTE FIXOS)
# =====================
def objective(trial, tamanho_janela, horizonte_previsao):
    hidden_size = trial.suggest_int('hidden_size', 16, 256)
    num_layers  = trial.suggest_int('num_layers', 1, 3)
    dropout     = trial.suggest_float('dropout', 0.0, 0.5)
    lr          = trial.suggest_float('lr', 1e-5, 1e-2)

    X_tr, y_tr = gerar_janelas(valores_treino, tamanho_janela, horizonte_previsao)
    X_va, y_va = gerar_janelas(valores_validacao, tamanho_janela, horizonte_previsao)
    if len(X_tr)==0 or len(X_va)==0:
        return float('inf')

    mdl = run_model(tamanho_janela, horizonte_previsao,
                    X_tr, y_tr, X_va, y_va,
                    hidden_size, num_layers, dropout, lr)
    mdl.eval()
    with torch.no_grad():
        y_pred = mdl(torch.Tensor(X_va).to(device)).cpu().numpy()
    return np.sqrt(mean_squared_error(y_va, y_pred))

# =====================
# 10. OTIMIZAÇÃO PARA 9 CASOS FIXOS
# =====================
casos = [(12,12),(24,12),(48,12),
         (12,24),(24,24),(48,24),
         (12,48),(24,48),(48,48)]

best_params = {}
for janela, horizonte in casos:
    print(f"\nOtimizando LSTM para janela={janela}, horizonte={horizonte}...")
    study = optuna.create_study(direction='minimize')
    start = time.time()
    study.optimize(lambda tr: objective(tr, janela, horizonte), n_trials=50)
    print(f"→ tempo: {time.time()-start:.1f}s, params: {study.best_params}")
    best_params[(janela,horizonte)] = study.best_params

pd.DataFrame([
    {'tamanho_janela': j, 'horizonte_previsao': h, **p}
    for (j,h), p in best_params.items()
]).to_csv(f"{save_path}/lstm_best_params.csv", index=False)

# =====================
# 11. SELEÇÃO POR CENTRÓIDE
# =====================
def pick_params(jan, hor, best_params):
    dists = {
      (j,h): np.hypot(jan-j, hor-h)
      for (j,h) in best_params
    }
    nearest = min(dists, key=dists.get)
    return best_params[nearest]

# =====================
# 12. AVALIAÇÃO FINAL COM MÉTRICAS
# =====================
results = []
for janela in range(1,49):
    for horizonte in range(1,49):
        X_tr, y_tr = gerar_janelas(valores_treino, janela, horizonte)
        X_va, y_va = gerar_janelas(valores_validacao, janela, horizonte)
        X_te, y_te = gerar_janelas(valores_teste, janela, horizonte)
        if min(len(X_tr),len(X_va),len(X_te))==0:
            continue

        # combine treino+validação para treinamento final
        X_comb = np.vstack((X_tr, X_va))
        y_comb = np.vstack((y_tr, y_va))

        params = pick_params(janela, horizonte, best_params)
        mdl = run_model(janela, horizonte,
                        X_comb, y_comb, X_te, y_te,
                        params['hidden_size'], params['num_layers'],
                        params['dropout'], params['lr'])
        mdl.eval()
        with torch.no_grad():
            y_pred = mdl(torch.Tensor(X_te).to(device)).cpu().numpy()

        mse  = mean_squared_error(y_te, y_pred)
        rmse = np.sqrt(mse)
        mae  = mean_absolute_error(y_te, y_pred)
        mape = (np.abs((y_te - y_pred)/(y_te + 1e-8)).mean())*100

        results.append({
            'tamanho_janela': janela,
            'horizonte_previsao': horizonte,
            'mae': mae, 'mse': mse,
            'rmse': rmse, 'mape': mape
        })

df_res = pd.DataFrame(results)
df_res.to_csv(f"{save_path}/lstm_evaluation.csv", index=False)
print("Resultados LSTM salvos em lstm_evaluation.csv")